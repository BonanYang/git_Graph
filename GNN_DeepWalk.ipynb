{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMQ7Gio46x80iMJr2Wo1Qsi",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/BonanYang/git_Graph/blob/master/GNN_DeepWalk.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PnvOZxAKXKzZ",
        "outputId": "929033e6-7c5a-4e7c-d38e-47a503315643"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting gensim\n",
            "  Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (8.4 kB)\n",
            "Requirement already satisfied: numpy>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (2.0.2)\n",
            "Requirement already satisfied: scipy>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.16.3)\n",
            "Requirement already satisfied: smart_open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.5.0)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart_open>=1.8.1->gensim) (2.0.1)\n",
            "Downloading gensim-4.4.0-cp312-cp312-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (27.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m27.9/27.9 MB\u001b[0m \u001b[31m49.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: gensim\n",
            "Successfully installed gensim-4.4.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import matplotlib as plt\n",
        "import random\n",
        "from tqdm import tqdm\n",
        "import torch\n",
        "from torch import nn as nn\n",
        "import torch.optim as optim\n",
        "import numpy as np\n",
        "from gensim.models import Word2Vec"
      ],
      "metadata": {
        "id": "vnPBZbiq3nAU"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df = pd.read_csv('seealsology-data.tsv',sep='\\t')\n",
        "G = nx.from_pandas_edgelist(df)\n"
      ],
      "metadata": {
        "id": "2-4ER_CTz4Ix"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yCmuun2qHpGQ",
        "outputId": "8485291c-7c01-4934-d961-162d53d64446"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['support-vector machine',\n",
              " 'fisher kernel',\n",
              " 'support vector machine',\n",
              " 'kernel machines',\n",
              " 'similarity learning',\n",
              " 'kernel trick']"
            ]
          },
          "metadata": {},
          "execution_count": 5
        }
      ],
      "source": [
        "def get_random_walk(node,length):\n",
        "  random_walk = [node]\n",
        "  for _ in range(length):\n",
        "    temp = list(G.neighbors(node))\n",
        "    temp = list(set(temp)-set(random_walk))\n",
        "    if len(temp) == 0:\n",
        "      break\n",
        "    rn = random.choice(temp)\n",
        "    random_walk.append(rn)\n",
        "    node = rn\n",
        "  return random_walk\n",
        "\n",
        "get_random_walk('support-vector machine', 5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "gamma = 10\n",
        "walk_len= 5\n",
        "data = []\n",
        "n = list(G.nodes())\n",
        "\n",
        "for i in tqdm(n):\n",
        "  for _ in range(gamma):\n",
        "    data.append(get_random_walk(i,walk_len))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kt0EQgYYm9ZM",
        "outputId": "15f5192a-8b7d-430f-a915-2b5d02134fd0"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 8560/8560 [00:02<00:00, 2873.59it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data[101]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LSO0FAfRpKpJ",
        "outputId": "d74f24c7-cfe2-4912-e0fe-d73e20b7b8dc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['space mapping',\n",
              " 'machine learning',\n",
              " 'gene expression programming',\n",
              " 'artificial intelligence',\n",
              " 'informatics (academic field)',\n",
              " 'robotics']"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Word2Vec(vector_size=256,\n",
        "                 window=4,\n",
        "                 sg=1,\n",
        "                 hs=0,\n",
        "                 negative=10,\n",
        "                 alpha=0.03,\n",
        "                 min_alpha=0.0007,\n",
        "                 seed=14\n",
        "                )"
      ],
      "metadata": {
        "id": "xEYEXfIoXEry"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.build_vocab(data, progress_per=2)\n",
        "model.train(data, total_examples=model.corpus_count, epochs=50, report_delay=1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bXQbAxy6XEuS",
        "outputId": "1730032c-414e-4a71-8693-aad0fccaf159"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(17825702, 17829400)"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5eA-PzHyXEw1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "uTUp903DXEzm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kgQEMSbKXE4T"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ywGbcX-oXE63"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8P6lJUTTXE9e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "zSjlxStXXFAV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "NnfAgUbHXFDH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "EDa4WWWdXFFv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "P_tOPHylXFIL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class W2v:\n",
        "  def __init__(self,lr=0.001,embedding_dim=100,window_size=2):\n",
        "    self.window_size = window_size\n",
        "    self.embedding_dim = embedding_dim\n",
        "    self.lr =lr\n",
        "    self.device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
        "\n",
        "  def build_vocab(self,data):\n",
        "    vocab = set()\n",
        "    for i in data:\n",
        "      vocab.update(i)\n",
        "    vocab = list(vocab)\n",
        "    self.word2idx = {j:i for i,j in enumerate(vocab)}\n",
        "    self.idx2word = {i:j for i,j in enumerate(vocab)}\n",
        "    self. vocab_size = len(vocab)\n",
        "    return vocab\n",
        "\n",
        "  def training_data(self,data):\n",
        "    training_d = []\n",
        "    for d in data:\n",
        "      for i in range(self.window_size,len(d)-self.window_size):\n",
        "        center_word = d[i]\n",
        "        for j in range(i-self.window_size,i+self.window_size+1):\n",
        "          if j!= i:\n",
        "            context_word = d[j]\n",
        "            training_d.append((d[i],d[j]))\n",
        "    return training_d\n",
        "\n",
        "  def build_model(self):\n",
        "    class skipGram(nn.Module):\n",
        "      def __init__(self,vocab_size, embedding_dim):\n",
        "        super().__init__()\n",
        "        self.center_embedding = nn.Embedding(vocab_size,embedding_dim)\n",
        "        self.context_embedding = nn.Embedding(vocab_size,embedding_dim)\n",
        "\n",
        "      def forward(self,center_words,context_words):\n",
        "        center_embeds = self.center_embedding(center_words)\n",
        "        context_embeds = self.context_embedding(context_words)\n",
        "        score = torch.sum(center_embeds * context_embeds, dim=1)\n",
        "        return score\n",
        "\n",
        "    self.model = skipGram(self.vocab_size,self.embedding_dim).to(self.device)\n",
        "    self.optimizer = optim.Adam(self.model.parameters(), lr=self.lr)\n",
        "    self.loss_function = nn.BCEWithLogitsLoss()\n",
        "\n",
        "  def train(self,data,epochs=5,batch_size=10,negative_samples=5):\n",
        "    self.build_vocab(data)\n",
        "    t_data = self.training_data(data)\n",
        "    self.build_model()\n",
        "    self.model.train()\n",
        "    for e in range(epochs):\n",
        "      total_loss = 0\n",
        "      np.random.shuffle(t_data)\n",
        "      for j in range(0,len(t_data),batch_size):\n",
        "        batch = t_data[j:j+batch_size]\n",
        "        center_words = []\n",
        "        context_words = []\n",
        "        labels = []\n",
        "        for cent,ctx in batch:\n",
        "          cent_idx = self.word2idx[cent]\n",
        "          ctx_idx = self.word2idx[ctx]\n",
        "          center_words.append(cent_idx)\n",
        "          context_words.append(ctx_idx)\n",
        "          labels.append(1.0)\n",
        "\n",
        "          for _ in range(negative_samples):\n",
        "              neg_context = np.random.randint(0, self.vocab_size)\n",
        "              center_words.append(cent_idx)\n",
        "              context_words.append(neg_context)\n",
        "              labels.append(0.0)\n",
        "\n",
        "        center_words = torch.tensor(center_words, dtype=torch.long).to(self.device)\n",
        "        context_words = torch.tensor(context_words, dtype=torch.long).to(self.device)\n",
        "        labels = torch.tensor(labels, dtype=torch.float).to(self.device)\n",
        "        self.optimizer.zero_grad()\n",
        "        scores = self.model(center_words, context_words)\n",
        "        loss = self.loss_function(scores, labels)\n",
        "        loss.backward()\n",
        "        self.optimizer.step()\n",
        "        total_loss += loss.item()\n",
        "\n",
        "\n",
        "      avg_loss = total_loss / (len(t_data) // batch_size)\n",
        "      print(f'Epoch {e+1}/{epochs}, Loss: {avg_loss:.4f}')\n",
        "\n",
        "\n",
        "\n",
        "  def get_word_emb():\n",
        "    pass\n",
        "\n"
      ],
      "metadata": {
        "id": "oX2lYeQC3bOe"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = W2v()\n",
        "model.train(data)\n",
        "# a,b,c = model.train(data)\n",
        "# # model.build_vocab(data)\n",
        "# # model.training_data(data)\n",
        "# # model.build_model()\n",
        "# a.shape,b.shape,c.shape\n",
        "# a[2]\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oYMyssqs36X1",
        "outputId": "3809c9e4-e649-4503-89d5-19809361d658"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5, Loss: 3.1828\n",
            "Epoch 2/5, Loss: 1.7133\n",
            "Epoch 3/5, Loss: 0.5726\n",
            "Epoch 4/5, Loss: 0.2574\n",
            "Epoch 5/5, Loss: 0.1501\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "5nfevx1OMF9X"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}